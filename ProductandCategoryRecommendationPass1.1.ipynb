{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProductandCategoryRecommendationPass1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOlO8Vpp28Yz"
      },
      "source": [
        "# Even If you wish to run the program multiple times, run the code below this block only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZC9Kf_yXN-J"
      },
      "source": [
        "\n",
        "\n",
        "# Import all the Libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import datetime \n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import matplotlib.dates as mdates\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "# Importing the Events File and segregating the events into various columns\n",
        "events=pd.read_csv(\"/content/drive/MyDrive/Kaggle/events.csv\") \n",
        "events_copy=events\n",
        "events_dummies=pd.get_dummies(events_copy.event)    #To segregate the events into various columns\n",
        "events_copy_withdummies=pd.concat([events_copy,events_dummies],axis=1)\n",
        "events_copy_withdummies.drop([\"event\",\"timestamp\"],axis=1,inplace=True)\n",
        "events=events_copy_withdummies\n",
        "\n",
        "\n",
        "#Relating Item_ID with Category_ID\n",
        "\n",
        "df_item_prop_part1=pd.read_csv(\"/content/drive/MyDrive/Kaggle/item_properties_part1.csv\")\n",
        "df_item_prop_part2=pd.read_csv(\"/content/drive/MyDrive/Kaggle/item_properties_part2.csv\")\n",
        "df_itemsprop=df_item_prop_part1.append(df_item_prop_part2)  #Merge both property files to a single file\n",
        "df_itemsprop.reset_index(inplace=True)\n",
        "it_cat=df_itemsprop[df_itemsprop.property==\"categoryid\"].drop([\"index\",\"timestamp\",\"property\"],axis=1)\n",
        "it_cat_sort=it_cat.sort_values(\"itemid\").reset_index().drop(\"index\",axis=1)\n",
        "it_and_cat=it_cat_sort.drop_duplicates()\n",
        "it_and_cat.reset_index(inplace=True)\n",
        "for i in it_and_cat.index:\n",
        "  it_and_cat.at[i,\"value\"]=int(it_and_cat.iloc[i].value)\n",
        "\n",
        "\n",
        "# Merging the Category with events\n",
        "it_and_cat_copy=it_and_cat\n",
        "events_with_cat=events.merge(it_and_cat_copy,how=\"inner\",on=\"itemid\")\n",
        "events_with_cat=events_with_cat.rename(columns={'value':'categoryid'})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Perform the Apriori Algorithm with the Events File\n",
        "\n",
        "\n",
        "events_with_cat_grouping=events_with_cat[events_with_cat[\"transactionid\"].notna()==True].groupby([\"visitorid\",\"categoryid\"])[\"transaction\"].sum()\n",
        "events_with_cat_grouping=events_with_cat_grouping.unstack()\n",
        "events_with_cat_grouping=events_with_cat_grouping.fillna(0)\n",
        "def hot_encode(x):\n",
        "\tif(x<= 0):\n",
        "\t\treturn 0\n",
        "\tif(x>= 1):\n",
        "\t\treturn 1\n",
        "events_with_cat_grouping_encoded=events_with_cat_grouping.applymap(hot_encode)\n",
        "frq_items = apriori(events_with_cat_grouping_encoded, min_support = 0.0020, use_colnames = True)\n",
        "# Collecting the inferred rules in a dataframe\n",
        "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
        "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# To Form a dataframe outof all the antecedents and cosequents\n",
        "\n",
        "rules.sort_values([\"antecedent support\"],ascending=False)\n",
        "rules_1=rules.drop([\"antecedent support\",\"consequent support\",\"support\",\"confidence\",\"lift\",\"leverage\",\"conviction\"],axis=1)\n",
        "rules_1.sort_index(inplace=True)\n",
        "\n",
        "df_x=pd.DataFrame(None)\n",
        "df_y=pd.DataFrame(None)\n",
        "keys={}\n",
        "for i in events_with_cat[\"categoryid\"].unique():\n",
        "    keys[i]=0\n",
        "\n",
        "for i in rules_1.index:\n",
        "    x=rules_1[\"antecedents\"].iloc[i]\n",
        "    y=rules_1[\"consequents\"].iloc[i]\n",
        "    for j in x:\n",
        "        for k in y:\n",
        "            df_y.at[keys[j],j]=k\n",
        "            keys[j]=keys[j]+1\n",
        "            \n",
        "df_y=df_y.fillna(-1).astype(int)\n",
        "\n",
        "\n",
        "df_z=it_and_cat\n",
        "df_z.rename(columns={'value':'categoryid'},inplace=True)\n",
        "\n",
        "for i in df_z.categoryid.unique():\n",
        "    if i not in df_y.columns:\n",
        "        df_y[i]=-1\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWDWitLw3NEA"
      },
      "source": [
        "# You can run this block of code multiple times\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayHVauwdXMa_",
        "outputId": "4dd9f6dc-88f5-49ef-9f3b-87f8f45a8d33"
      },
      "source": [
        "\n",
        "def common(list1,list2):\n",
        "    intersection=(set(list1).intersection(list2))\n",
        "    x=list(intersection)\n",
        "    return x\n",
        "\n",
        "def commoncategory(li): \n",
        "    c_category=[]\n",
        "    c_category=c_category+(df_y[li[0]]).tolist()\n",
        "    for i in li:\n",
        "        apr=df_y[i]\n",
        "        intersection=common(c_category,apr)\n",
        "        c_category.clear()\n",
        "        c_category=c_category+intersection\n",
        "    return c_category\n",
        "\n",
        "\n",
        "def takecatinput():\n",
        "    print(\"Enter the Category_ID\")\n",
        "    str =  (input (\"Enter comma separated integers: \"))\n",
        "    li = []\n",
        "    listx = str.split (\",\")\n",
        "    for z in listx:\n",
        "        li.append(int(z))\n",
        "    return li\n",
        "        \n",
        "        \n",
        "        \n",
        "def takeiteminput():\n",
        "    print(\"Enter the Item_ID\")\n",
        "    str =  (input (\"Enter comma separated integers: \"))\n",
        "    li = []\n",
        "    listx = str.split (\",\")\n",
        "    for z in listx:\n",
        "        li.append(int(z))\n",
        "    \n",
        "    cat_items=[]\n",
        "    for j in li:\n",
        "        cat_items=cat_items+list(df_z[df_z.itemid==j].categoryid.unique())    \n",
        "    cat_items_unique=set(cat_items)\n",
        "    x=list(cat_items_unique)\n",
        "    return x\n",
        "    \n",
        "        \n",
        "def takeinput():\n",
        "    str=input(\"Enter 0 for ItemID and 1 for CategoryID\")\n",
        "    x=int(str)\n",
        "    y=int\n",
        "    if x==0:\n",
        "        y=takeiteminput()\n",
        "        return y\n",
        "    elif x==1:\n",
        "        y=takecatinput()\n",
        "        return y\n",
        "    else:\n",
        "        print(\"Wrong Input. Please Try Again\",\"\\n\")\n",
        "        takeinput()\n",
        "\n",
        "        \n",
        "        \n",
        "def finalprocessing(commonapriori):\n",
        "    final_items=[]    \n",
        "    for i in commonapriori:\n",
        "        final_items=final_items+df_z[df_z[\"categoryid\"]==i].itemid.tolist()\n",
        "    return(finalitems)\n",
        "    \n",
        "\n",
        "def all_in_each_cat(catlist):\n",
        "    final_list=[]\n",
        "    for i in catlist:\n",
        "        final_list=final_list+df_z[df_z[\"categoryid\"]==i].itemid.unique().tolist()\n",
        "    return final_list\n",
        "    \n",
        "    \n",
        "\n",
        "def top5(commonapriori,categorylist):\n",
        "    if len(commonapriori)>5:\n",
        "        df_temp=pd.DataFrame(None)\n",
        "        for j in categorylist:\n",
        "            for i in rules.index:\n",
        "                if j in rules.iloc[i].antecedents:\n",
        "                    df_temp=df_temp.append(rules.iloc[i])\n",
        "        \n",
        "        df_temp1=pd.DataFrame(None)\n",
        "        df_temp.reset_index(inplace=True)\n",
        "        for i in df_temp.index:\n",
        "            for j in df_temp.iloc[i].consequents:\n",
        "                if j in commonapriori:\n",
        "                    df_temp1=df_temp1.append(df_temp.iloc[i])\n",
        "                    break\n",
        "        # print(df_temp1)\n",
        "        df_temp1.drop(\"index\",axis=1,inplace=True)\n",
        "        df_temp1.reset_index(inplace=True)\n",
        "        df_deal=df_temp1\n",
        "        df_deal.drop(\"index\",axis=1,inplace=True)\n",
        "       \n",
        "\n",
        "        confidence={}\n",
        "        count={}\n",
        "\n",
        "        for i in commonapriori:\n",
        "            confidence[i]=0\n",
        "            count[i]=0\n",
        "\n",
        "        for i in df_deal.index:\n",
        "            for j in df_deal.iloc[i].consequents:\n",
        "                if j in commonapriori:\n",
        "                    confidence[j]=confidence[j]+df_deal.iloc[i].confidence\n",
        "                    count[j]=count[j]+1\n",
        "\n",
        "\n",
        "        commonapriori_conf=[]\n",
        "\n",
        "        for i in commonapriori:\n",
        "            commonapriori_conf.append(confidence[i]/count[i])\n",
        "\n",
        "\n",
        "\n",
        "        conf_to_cat={}\n",
        "        i=0\n",
        "        while i<len(commonapriori):\n",
        "            conf_to_cat[commonapriori_conf[i]]=commonapriori[i]\n",
        "            i=i+1\n",
        "\n",
        "        commonapriori_conf.sort(reverse=True)\n",
        "        commonapriori_conf\n",
        "\n",
        "        cat_final=[]\n",
        "        j=0\n",
        "        while j<5:\n",
        "            cat_final.append(conf_to_cat[commonapriori_conf[j]])\n",
        "            j=j+1\n",
        "\n",
        "        return cat_final\n",
        "  \n",
        "    \n",
        "allcorrectindex=False  \n",
        "\n",
        "\n",
        "while allcorrectindex==False: \n",
        "  allcorrectindex=True       \n",
        "  categorylist=takeinput()  \n",
        "  catlistemergency=categorylist.copy()\n",
        "  commonapriori=[]\n",
        "\n",
        "\n",
        "  for i in categorylist:\n",
        "    if df_z[df_z[\"categoryid\"]==i].empty:\n",
        "      print(\"Some of the categoryid's that you entered don't exist \")\n",
        "      allcorrectindex=False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if allcorrectindex==True:\n",
        "  while len(commonapriori)==0:\n",
        "      commonapriori=commoncategory(categorylist)\n",
        "      if -1 in commonapriori:\n",
        "          commonapriori.remove(-1)\n",
        "      if len(commonapriori)==0:\n",
        "          import random\n",
        "          categorylist.remove(random.choice(categorylist))\n",
        "      if len(categorylist)==0:\n",
        "          break\n",
        "\n",
        "          \n",
        "  if len(commonapriori)>5:         \n",
        "    commonapriori=top5(commonapriori,categorylist)\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  if len(categorylist)!=0:  \n",
        "      print(\"The Category Recommendations are: \",commonapriori)\n",
        "      itemsq=input(\"Do You Want a list of items in it (Y/N)\")\n",
        "      if itemsq==\"Y\" or itemsq==\"y\":\n",
        "          final_item_list=finalprocessing(commonapriori)    \n",
        "          print(set(final_itemlist))\n",
        "      \n",
        "  else:\n",
        "      print(\"Sorry,We Could not Find any category recommendation\")\n",
        "      x=(input(\"To see the items in the same category as the items you have purchased, Enter 1\"))\n",
        "      if(x=='1'):\n",
        "          final_item_list=all_in_each_cat(catlistemergency)\n",
        "          print(set(final_item_list))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter 0 for ItemID and 1 for CategoryID0\n",
            "Enter the Item_ID\n",
            "Enter comma separated integers: 29,141\n",
            "The Category Recommendations are:  [959, 1483, 1135, 57, 618]\n",
            "Do You Want a list of items in it (Y/N)N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJmdXuTkcrK"
      },
      "source": [
        "1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8J0OzDsYN3v"
      },
      "source": [
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muh36piqngT5"
      },
      "source": [],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6tr5VvInh-l"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkoAU3YkniCH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJBf_Ep5niHp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ennmyu_QpOCw"
      },
      "source": [],
      "execution_count": 46,
      "outputs": []
    }
  ]
}